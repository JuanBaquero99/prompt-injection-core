# Fase 1 - Entrada y ManipulaciÃ³n de Datos

Enfocada en amenazas que ocurren antes o durante el procesamiento de la entrada al modelo.

## ğŸ¯ Amenazas Cubiertas

### 1.1 Prompt Injection âœ… **COMPLETADO**
- **Estado**: Completamente implementado y funcional
- **UbicaciÃ³n**: `./prompt_injection/`
- **Capacidades**:
  - DetecciÃ³n multicapa (regex, ML, adversarial)
  - Modelo RandomForest optimizado
  - DetecciÃ³n de camuflaje educativo
  - Pipeline completo de investigaciÃ³n a producciÃ³n

### 1.3 Adversarial Examples âœ… **COMPLETADO - EVALUACIÃ“N EMPÃRICA**
- **Estado**: Framework PERSONA completamente implementado y evaluado
- **Objetivo**: Generar y evaluar ataques adversariales contra modelos visiÃ³n-lenguaje
- **UbicaciÃ³n**: `./adversarial_examples/`
- **Capacidades**:
  - **OCR Injection**: 4 tÃ©cnicas (invisible text, steganographic, transparent, microscopic)
  - **Pipeline Positioning**: 4 tÃ©cnicas (preprocessing, feature extraction, attention hijacking, multi-stage)
  - **EvaluaciÃ³n sistemÃ¡tica**: 40 ataques contra LLaVA-1.5-7B
  - **Multi-prompt testing**: 3 estrategias por ataque
  - **Success detection**: Algoritmo de 67 indicadores
- **Resultados empÃ­ricos**:
  - ğŸ¯ **12.5% success rate general** (2/16 ataques exitosos)
  - ğŸ” **Pipeline positioning: 25% efectividad** vs OCR injection: 0%
  - ğŸ† **Preprocessing injection** identificada como tÃ©cnica mÃ¡s vulnerable
  - ğŸ“Š **Primera evaluaciÃ³n sistemÃ¡tica** de vulnerabilidades en LLaVA

### 5.1 ValidaciÃ³n y Filtrado de Inputs ğŸ“ **PLANEADO**  
- **Estado**: En planificaciÃ³n
- **Objetivo**: Sistema robusto de validaciÃ³n y sanitizaciÃ³n de entradas
- **UbicaciÃ³n futura**: `./input_validation/`

## ğŸš€ Quick Start

### Prompt Injection
```bash
cd prompt_injection
python demo_complete.py
```

### EvaluaciÃ³n de Rendimiento
```bash
cd prompt_injection
python evaluate_model.py
```

## ğŸ“Š MÃ©tricas Actuales

### Prompt Injection
- âœ… **PrecisiÃ³n**: 100% (cero falsos positivos)
- âš ï¸ **Recall**: 30% (detecta ataques directos)
- âœ… **Especificidad**: 100% (no molesta usuarios legÃ­timos)

### Adversarial Examples (Framework PERSONA)
- ğŸ¯ **Success Rate General**: 12.5% (2/16 ataques exitosos)
- ğŸ“Š **Pipeline Positioning**: 25% efectividad (5/20 ataques)
- ğŸš« **OCR Injection**: 0% efectividad (0/20 ataques)
- ğŸ” **Preprocessing Injection**: 40% efectividad (2/5 ataques)
- ğŸ“ˆ **Confidence Score**: 0.900 en ataques exitosos
- ğŸ“‹ **Statistical Significance**: p < 0.001 (diferencia altamente significativa)

## ğŸ—‚ï¸ Estructura de Carpetas

```
phase1_input_security/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ prompt_injection/            # Sistema completo de detecciÃ³n
â”‚   â”œâ”€â”€ core.py                 # Motor principal
â”‚   â”œâ”€â”€ detectors/              # Detectores especializados
â”‚   â”œâ”€â”€ scanner/                # Scanner modular
â”‚   â”œâ”€â”€ data/                   # Datasets y modelos
â”‚   â”œâ”€â”€ examples/               # Ejemplos de uso
â”‚   â”œâ”€â”€ research/               # InvestigaciÃ³n avanzada
â”‚   â”œâ”€â”€ scripts/                # Scripts de utilidad
â”‚   â””â”€â”€ tests/                  # Suite de pruebas
â”œâ”€â”€ adversarial_examples/        # âœ… Generadores de ataques adversariales
â”‚   â”œâ”€â”€ attack_generators/      # Generadores por tÃ©cnica
â”‚   â”œâ”€â”€ test_cases/             # Ataques generados
â”‚   â”œâ”€â”€ evaluation/             # MÃ©tricas de evaluaciÃ³n
â”‚   â””â”€â”€ models/                 # Interfaces para testing
â””â”€â”€ input_validation/           # [FUTURO] ValidaciÃ³n de inputs
```

## ğŸ”¬ InvestigaciÃ³n Activa

### Prompt Injection
- **Educational Disguise Detection**: Primer sistema en detectar ataques camuflados
- **AnÃ¡lisis semÃ¡ntico**: IntenciÃ³n real vs apariencia
- **Pipeline adaptativo**: InvestigaciÃ³n â†’ producciÃ³n automatizado

### Adversarial Examples - PERSONA Framework
- **Primera evaluaciÃ³n sistemÃ¡tica**: LLaVA-1.5-7B vulnerabilities
- **Pipeline positioning attacks**: MÃ¡s efectivos que mÃ©todos tradicionales
- **Multi-modal security**: IntersecciÃ³n visiÃ³n-lenguaje
- **Paper acadÃ©mico**: En preparaciÃ³n para conference submission

### PrÃ³ximos Pasos
- ğŸ” **Refinamiento de ataques exitosos**: Mejorar preprocessing injection
- ğŸ¯ **ExpansiÃ³n de evaluaciÃ³n**: GPT-4V, BLIP-2, Qwen-VL
- ğŸ›¡ï¸ **Desarrollo de defensas**: Contramedidas especÃ­ficas
- ğŸ“„ **PublicaciÃ³n acadÃ©mica**: Documentar hallazgos

## ğŸ“ Contacto

Para colaboraciones especÃ­ficas en Fase 1:
- **Juan Pablo Baquero** - baquerojuan99@gmail.com
