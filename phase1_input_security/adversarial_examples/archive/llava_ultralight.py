#!/usr/bin/env python3
"""
LLaVA Ultra-Light Testing
========================

VersiÃ³n ultra-optimizada de LLaVA con tÃ©cnicas agresivas de optimizaciÃ³n
de memoria. Para sistemas con recursos muy limitados.

Estrategias:
1. Carga progresiva
2. Solo componentes esenciales  
3. LiberaciÃ³n inmediata de memoria
4. Logging detallado para debugging

Autor: PERSONA Framework Team
"""

import os
import sys
import json
import time
import gc
from typing import Dict, List, Any, Optional
from datetime import datetime
from PIL import Image

# Limpiar memoria antes de importar torch
gc.collect()

print("ğŸ¦™ LLaVA Ultra-Light Testing")
print("="*40)
print("ğŸ”§ Importando dependencias...")

try:
    import torch
    print(f"   âœ… PyTorch {torch.__version__}")
    
    # Configurar torch inmediatamente
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    
    # Si hay CUDA, limpiar cache
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"   ğŸ® GPU: {gpu_mem:.1f}GB VRAM disponible")
    else:
        print("   ğŸ’» CPU mode - No GPU detectada")
        
except ImportError as e:
    print(f"   âŒ Error importando PyTorch: {e}")
    sys.exit(1)

# Import progresivo de transformers
try:
    print("   ğŸ“¦ Importando transformers...")
    from transformers import AutoProcessor, LlavaForConditionalGeneration
    print("   âœ… Transformers importado")
except ImportError as e:
    print(f"   âŒ Error importando transformers: {e}")
    sys.exit(1)

class UltraLightLLaVATester:
    """Tester ultra-optimizado para sistemas con pocos recursos."""
    
    def __init__(self):
        """Inicializa el tester ultra-light."""
        self.model = None
        self.processor = None
        self.device = "cpu"  # Forzar CPU por ahora
        self.model_loaded = False
        self.attack_dir = "real_testing_results"
        
        print("ğŸš€ Ultra-Light Tester inicializado")
        
        # Verificar ataques disponibles
        self._check_available_attacks()
    
    def _check_available_attacks(self):
        """Verifica ataques disponibles."""
        if not os.path.exists(self.attack_dir):
            print(f"   âš ï¸  Directorio {self.attack_dir} no encontrado")
            return
        
        files = [f for f in os.listdir(self.attack_dir) if f.endswith('.png')]
        print(f"   ğŸ“Š {len(files)} ataques disponibles")
        
        # Mostrar algunos ejemplos
        for i, f in enumerate(files[:3]):
            print(f"   â€¢ {f}")
    
    def attempt_minimal_load(self) -> bool:
        """
        Intenta cargar LLaVA con configuraciÃ³n mÃ­nima.
        
        Returns:
            True si carga exitosamente
        """
        print("\nğŸ¦™ Intentando carga ultra-minimal...")
        
        try:
            model_id = "llava-hf/llava-1.5-7b-hf"
            
            # Limpiar toda la memoria disponible
            gc.collect()
            
            print("   ğŸ“ Cargando procesador (minimal)...")
            self.processor = AutoProcessor.from_pretrained(
                model_id,
                low_cpu_mem_usage=True
            )
            print("   âœ… Procesador cargado")
            
            print("   ğŸ§  Cargando modelo (ultra-optimizado)...")
            print("      â³ Esto puede tomar varios minutos...")
            
            # ConfiguraciÃ³n ultra-conservadora
            self.model = LlavaForConditionalGeneration.from_pretrained(
                model_id,
                device_map="cpu",
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True,
                offload_folder="./tmp_offload"
            )
            
            print("   âœ… Modelo cargado exitosamente!")
            
            # Configurar para inferencia
            self.model.eval()
            self.model_loaded = True
            
            # Limpiar cache
            gc.collect()
            
            return True
            
        except Exception as e:
            print(f"   âŒ Error en carga minimal: {e}")
            return self._try_emergency_config()
    
    def _try_emergency_config(self) -> bool:
        """ConfiguraciÃ³n de emergencia."""
        print("\nğŸš¨ Intentando configuraciÃ³n de emergencia...")
        
        try:
            # Si nada funciona, al menos verificar que las dependencias estÃ©n OK
            print("   ğŸ” Verificando dependencias...")
            print(f"   â€¢ PyTorch: {torch.__version__}")
            print(f"   â€¢ Transformers disponible: âœ…")
            
            # Intentar una carga muy bÃ¡sica
            from transformers import pipeline
            print("   ğŸ’­ Intentando pipeline bÃ¡sico...")
            
            # No cargar el modelo completo, solo verificar que funciona
            print("   âš ï¸  Modelo no cargado - dependencias OK")
            print("   ğŸ’¡ Sugerencias:")
            print("      1. Cerrar todos los programas no esenciales")
            print("      2. Reiniciar el sistema")
            print("      3. Aumentar memoria virtual de Windows")
            print("      4. Usar GPT-4V API como alternativa ($0.50 = ~$2,000 COP)")
            
            return False
            
        except Exception as e:
            print(f"   âŒ ConfiguraciÃ³n de emergencia fallÃ³: {e}")
            return False
    
    def test_basic_functionality(self) -> Dict[str, Any]:
        """
        Test bÃ¡sico de funcionalidad (si el modelo estÃ¡ cargado).
        
        Returns:
            Resultados del test
        """
        if not self.model_loaded:
            return {
                "error": "Modelo no cargado",
                "suggestions": [
                    "Liberar mÃ¡s memoria RAM",
                    "Cerrar otros programas", 
                    "Reiniciar sistema",
                    "Usar GPT-4V API (~$2,000 COP para 50 tests)"
                ]
            }
        
        print("ğŸ¯ Ejecutando test bÃ¡sico...")
        
        try:
            # Buscar una imagen de test
            test_images = [f for f in os.listdir(self.attack_dir) if f.endswith('.png')][:1]
            
            if not test_images:
                return {"error": "No hay imÃ¡genes de test disponibles"}
            
            test_image_path = os.path.join(self.attack_dir, test_images[0])
            
            # Cargar imagen
            image = Image.open(test_image_path).convert('RGB')
            
            # Prompt simple
            prompt = "USER: <image>\nWhat do you see in this image? ASSISTANT:"
            
            # Procesar
            inputs = self.processor(text=prompt, images=image, return_tensors="pt")
            
            # Generar respuesta
            start_time = time.time()
            
            with torch.no_grad():
                generate_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=50,  # Solo 50 tokens para test
                    do_sample=False,
                    pad_token_id=self.processor.tokenizer.eos_token_id
                )
            
            inference_time = time.time() - start_time
            
            # Decodificar
            response = self.processor.batch_decode(
                generate_ids, 
                skip_special_tokens=True
            )[0]
            
            if "ASSISTANT:" in response:
                response = response.split("ASSISTANT:")[-1].strip()
            
            return {
                "success": True,
                "image_tested": test_image_path,
                "model_response": response,
                "inference_time": inference_time,
                "device": self.device
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "model_loaded": self.model_loaded
            }

def main():
    """FunciÃ³n principal ultra-light."""
    print("\nğŸ¦™ INICIANDO TESTING ULTRA-LIGHT")
    print("="*40)
    
    try:
        # Inicializar tester
        tester = UltraLightLLaVATester()
        
        # Intentar carga minimal
        print("\nğŸ“¥ Intentando carga ultra-optimizada...")
        success = tester.attempt_minimal_load()
        
        if success:
            print("\nğŸ‰ Â¡Modelo cargado exitosamente!")
            
            # Ejecutar test bÃ¡sico
            result = tester.test_basic_functionality()
            
            if "error" not in result:
                print(f"\nâœ… TEST EXITOSO!")
                print(f"   ğŸ“ Respuesta: {result['model_response']}")
                print(f"   âš¡ Tiempo: {result['inference_time']:.2f}s")
                print(f"   ğŸ–¥ï¸  Dispositivo: {result['device']}")
                
                # Guardar resultado
                filename = f"llava_ultralight_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(result, f, indent=2, ensure_ascii=False)
                
                print(f"   ğŸ’¾ Resultado guardado: {filename}")
                print("\nğŸš€ Â¡LLaVA funcionando localmente!")
                
            else:
                print(f"\nâŒ Error en test: {result['error']}")
                if "suggestions" in result:
                    print("   ğŸ’¡ Sugerencias:")
                    for suggestion in result["suggestions"]:
                        print(f"      â€¢ {suggestion}")
        
        else:
            print("\nâŒ No se pudo cargar el modelo")
            print("\nğŸ“Š ESTADO ACTUAL:")
            print("   â€¢ Dependencias: âœ… Instaladas correctamente")
            print("   â€¢ Modelo: âŒ No se pudo cargar (memoria insuficiente)")
            print("\nğŸ’¡ OPCIONES DISPONIBLES:")
            print("   1. ğŸ†“ Liberar mÃ¡s RAM y reintentar")
            print("   2. ğŸ’° GPT-4V API (~$2,000 COP = 50 tests)")
            print("   3. ğŸ“Š Usar resultados de anÃ¡lisis actual")
            
            # Mostrar estado de anÃ¡lisis actual
            print("\nğŸ“ˆ DATOS DISPONIBLES (de anÃ¡lisis previo):")
            print("   â€¢ 40 ataques generados (20 OCR + 20 Pipeline)")
            print("   â€¢ SofisticaciÃ³n Pipeline: 0.825/1.0")
            print("   â€¢ SofisticaciÃ³n OCR: 0.525/1.0") 
            print("   â€¢ Diferencia significativa: 57% mÃ¡s sofisticados")
            
    except Exception as e:
        print(f"\nâŒ Error crÃ­tico: {e}")
        print("\nğŸ’¡ Si el error persiste:")
        print("   â€¢ Reiniciar VS Code")
        print("   â€¢ Reiniciar sistema")
        print("   â€¢ Considerar GPT-4V API")

if __name__ == "__main__":
    main()
